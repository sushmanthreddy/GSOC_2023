{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q optuna\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-11T19:14:40.887169Z","iopub.execute_input":"2023-07-11T19:14:40.887642Z","iopub.status.idle":"2023-07-11T19:14:51.805715Z","shell.execute_reply.started":"2023-07-11T19:14:40.887598Z","shell.execute_reply":"2023-07-11T19:14:51.804475Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install  -q monai\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T19:14:51.809546Z","iopub.execute_input":"2023-07-11T19:14:51.809891Z","iopub.status.idle":"2023-07-11T19:15:03.183103Z","shell.execute_reply.started":"2023-07-11T19:14:51.809861Z","shell.execute_reply":"2023-07-11T19:15:03.181894Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q albumentations","metadata":{"execution":{"iopub.status.busy":"2023-07-11T19:15:03.185503Z","iopub.execute_input":"2023-07-11T19:15:03.185914Z","iopub.status.idle":"2023-07-11T19:15:14.242498Z","shell.execute_reply.started":"2023-07-11T19:15:03.185873Z","shell.execute_reply":"2023-07-11T19:15:14.241292Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q git+https://github.com/huggingface/transformers.git","metadata":{"execution":{"iopub.status.busy":"2023-07-11T19:15:14.246378Z","iopub.execute_input":"2023-07-11T19:15:14.246736Z","iopub.status.idle":"2023-07-11T19:15:45.836896Z","shell.execute_reply.started":"2023-07-11T19:15:14.246696Z","shell.execute_reply":"2023-07-11T19:15:45.835726Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os,sys\nimport numpy as np \nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom PIL import Image \nfrom tqdm.notebook import tqdm\nfrom IPython.display import clear_output","metadata":{"execution":{"iopub.status.busy":"2023-07-11T19:15:45.840196Z","iopub.execute_input":"2023-07-11T19:15:45.840579Z","iopub.status.idle":"2023-07-11T19:15:45.935987Z","shell.execute_reply.started":"2023-07-11T19:15:45.840540Z","shell.execute_reply":"2023-07-11T19:15:45.935048Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#all required torch libraries\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader,Dataset\nfrom torchvision import transforms,utils\nimport torchvision.transforms as transforms\nfrom torchvision.transforms import ToTensor\nfrom torchvision.transforms import ToPILImage\nfrom torch.utils.data.dataset import random_split\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torchvision.ops import masks_to_boxes\nfrom albumentations import Compose, Transpose, VerticalFlip, HorizontalFlip, RandomRotate90, ShiftScaleRotate, OpticalDistortion","metadata":{"execution":{"iopub.status.busy":"2023-07-11T19:15:45.937595Z","iopub.execute_input":"2023-07-11T19:15:45.937978Z","iopub.status.idle":"2023-07-11T19:15:48.356513Z","shell.execute_reply.started":"2023-07-11T19:15:45.937944Z","shell.execute_reply":"2023-07-11T19:15:48.355422Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\nimport time\nimport optuna\nimport csv\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\"finished\")\nfrom os import listdir\nfrom os.path import isfile, join","metadata":{"execution":{"iopub.status.busy":"2023-07-11T19:15:48.358278Z","iopub.execute_input":"2023-07-11T19:15:48.358654Z","iopub.status.idle":"2023-07-11T19:15:48.520478Z","shell.execute_reply.started":"2023-07-11T19:15:48.358621Z","shell.execute_reply":"2023-07-11T19:15:48.519371Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"finished\n","output_type":"stream"}]},{"cell_type":"code","source":"import monai","metadata":{"execution":{"iopub.status.busy":"2023-07-11T19:15:48.521870Z","iopub.execute_input":"2023-07-11T19:15:48.522223Z","iopub.status.idle":"2023-07-11T19:15:53.778394Z","shell.execute_reply.started":"2023-07-11T19:15:48.522188Z","shell.execute_reply":"2023-07-11T19:15:53.777420Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"def resize(path):\n  dirs = os.listdir( path )\n  for item in tqdm(dirs):\n    if os.path.isfile(path+item):\n      im = Image.open(path+item)\n      f, e = os.path.splitext(path+item)\n      imResize = im.resize((256,256), Image.NEAREST)\n      imResize.save(f+e, 'PNG', quality=100)\n      \nlabel_path =  \"/kaggle/input/nucleus-data-c-elegans/nucleus_data/segmentation_maps\"\noutput_features_path = \"/kaggle/input/nucleus-data-c-elegans/nucleus_data/features\"\nresize(label_path)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T19:15:53.779894Z","iopub.execute_input":"2023-07-11T19:15:53.780450Z","iopub.status.idle":"2023-07-11T19:15:53.850003Z","shell.execute_reply.started":"2023-07-11T19:15:53.780412Z","shell.execute_reply":"2023-07-11T19:15:53.848944Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6790 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b7d4587d6ad4d24b94908cbfc258869"}},"metadata":{}}]},{"cell_type":"code","source":"ids=[]\nlabel_filenames = [f for f in listdir(label_path) if isfile(join(label_path, f))]\nfeature_filenames = [f for f in listdir(output_features_path) if isfile(join(output_features_path, f))]\nfor i in range(len(feature_filenames)):\n  ids.append(feature_filenames[i][1:])\nprint(len(ids))\n\ndf = pd.DataFrame(ids ,columns=[\"file_ids\"])\ndf.to_csv('full_file_ids.csv', index=False)\n\n#sanity check\ndf = pd.read_csv('full_file_ids.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-11T19:15:53.854294Z","iopub.execute_input":"2023-07-11T19:15:53.854663Z","iopub.status.idle":"2023-07-11T19:16:00.040488Z","shell.execute_reply.started":"2023-07-11T19:15:53.854627Z","shell.execute_reply":"2023-07-11T19:16:00.039544Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"6756\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"     file_ids\n0  182_22.png\n1  167_27.png\n2   86_29.png\n3  154_16.png\n4   177_8.png","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>182_22.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>167_27.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>86_29.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>154_16.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>177_8.png</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport cv2\n\n# Read the CSV file\ndf = pd.read_csv('full_file_ids.csv')\n\n# Extract the file_ids column as a list\nids = df['file_ids'].tolist()\n\n# Filter non-empty file IDs\nnon_empty_ids = []\n\n\nfor file_id in ids:\n    mask_path = os.path.join(label_path, 'L' + file_id)\n    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n    if cv2.countNonZero(mask) > 0:\n        non_empty_ids.append(file_id)\n\n# Create a new DataFrame with non-empty file IDs\ndf_non_empty = pd.DataFrame(non_empty_ids, columns=[\"file_ids\"])\n\n# Save the non-empty file IDs to a new CSV file\ndf_non_empty.to_csv('file_ids.csv', index=False)\n\n# Read the file_ids CSV file\ndf = pd.read_csv('file_ids.csv')\n\n# Sort the file_ids column\ndf.sort_values(by='file_ids', inplace=True)\n\n# Display the first few rows of the sorted DataFrame\nprint(df.head())\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T19:16:00.042181Z","iopub.execute_input":"2023-07-11T19:16:00.042831Z","iopub.status.idle":"2023-07-11T19:16:09.207355Z","shell.execute_reply.started":"2023-07-11T19:16:00.042796Z","shell.execute_reply":"2023-07-11T19:16:09.206281Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"      file_ids\n2625  0_10.png\n1544  0_11.png\n2409  0_12.png\n1479  0_13.png\n2987  0_14.png\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install 'transformers[torch]'","metadata":{"execution":{"iopub.status.busy":"2023-07-11T19:16:09.208992Z","iopub.execute_input":"2023-07-11T19:16:09.209321Z","iopub.status.idle":"2023-07-11T19:16:20.302971Z","shell.execute_reply.started":"2023-07-11T19:16:09.209290Z","shell.execute_reply":"2023-07-11T19:16:20.301690Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.31.0.dev0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.12.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (5.4.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.5.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.28.2)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.3.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.64.1)\nRequirement already satisfied: torch!=1.12.0,>=1.9 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.0.0)\nRequirement already satisfied: accelerate>=0.20.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.20.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (2023.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.0.9)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2023.5.7)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"class SegmentationDataset(Dataset):\n    def __init__(self, csv, processor):\n        self.df = pd.read_csv(csv)\n        self.ids = self.df[\"file_ids\"]\n        self.processor = processor\n        \n\n    def __getitem__(self, idx):\n        image = Image.open(\"/kaggle/input/nucleus-data-c-elegans/nucleus_data/features/F\" + self.ids[idx])\n        mask = np.array(Image.open(\"/kaggle/input/nucleus-data-c-elegans/nucleus_data/segmentation_maps/L\" + self.ids[idx]))\n            \n\n        prompt = self.mask_to_boxes(mask)\n\n        inputs = self.processor(image, input_boxes=[prompt], return_tensors=\"pt\")\n        inputs = {k: v.squeeze(0) for k, v in inputs.items()}\n\n        inputs[\"ground_truth_mask\"] = mask\n\n        return inputs\n\n    def __len__(self):\n        return len(self.ids)\n    \n    \n    @staticmethod\n    def mask_to_boxes(mask):\n        obj_id=np.unique(mask)\n        obj_ids=obj_id[1:]\n        maskes = mask == obj_ids[:, None, None]\n        b_boxes=[]\n        num_objs=len(obj_ids)\n        for i in range(num_objs):\n            pos=np.nonzero(maskes[i])\n            xmin=np.min(pos[1])\n            xmax=np.max(pos[1])\n            ymin=np.min(pos[0])\n            ymax=np.max(pos[0])\n            b_boxes.append([xmin,ymin,xmax,ymax])\n        \n        return b_boxes\n            \n            ","metadata":{"execution":{"iopub.status.busy":"2023-07-11T19:16:20.305858Z","iopub.execute_input":"2023-07-11T19:16:20.306198Z","iopub.status.idle":"2023-07-11T19:16:20.321371Z","shell.execute_reply.started":"2023-07-11T19:16:20.306168Z","shell.execute_reply":"2023-07-11T19:16:20.320340Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from transformers import SamProcessor\n\nprocessor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")","metadata":{"execution":{"iopub.status.busy":"2023-07-11T19:16:20.322669Z","iopub.execute_input":"2023-07-11T19:16:20.323000Z","iopub.status.idle":"2023-07-11T19:16:20.518860Z","shell.execute_reply.started":"2023-07-11T19:16:20.322969Z","shell.execute_reply":"2023-07-11T19:16:20.517882Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_dataset = SegmentationDataset(csv = \"file_ids.csv\", processor=processor)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T19:16:20.520014Z","iopub.execute_input":"2023-07-11T19:16:20.520870Z","iopub.status.idle":"2023-07-11T19:16:20.535226Z","shell.execute_reply.started":"2023-07-11T19:16:20.520844Z","shell.execute_reply":"2023-07-11T19:16:20.534368Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"example = train_dataset[4235]\nfor k,v in example.items():\n  print(k,v.shape)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T19:16:20.536541Z","iopub.execute_input":"2023-07-11T19:16:20.537078Z","iopub.status.idle":"2023-07-11T19:16:20.631075Z","shell.execute_reply.started":"2023-07-11T19:16:20.537047Z","shell.execute_reply":"2023-07-11T19:16:20.630074Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"pixel_values torch.Size([3, 1024, 1024])\noriginal_sizes torch.Size([2])\nreshaped_input_sizes torch.Size([2])\ninput_boxes torch.Size([20, 4])\nground_truth_mask (256, 256)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\n\ndef collate_fn(batch):\n    images = []\n    masks = []\n    boxes = []\n\n    for item in batch:\n        images.append(item[\"pixel_values\"])\n        masks.append(item[\"ground_truth_mask\"])\n        boxes.append(item[\"input_boxes\"])\n\n    \n    images = torch.stack(images, dim=0)\n    masks = torch.stack([torch.from_numpy(mask) for mask in masks], dim=0)\n\n    \n    targets = []\n    max_num_boxes = max(len(b) for b in boxes)\n    for b in boxes:\n        padded_boxes = torch.cat([b, torch.zeros((max_num_boxes - len(b), 4))], dim=0)\n        targets.append(padded_boxes)\n\n    \n    targets = torch.stack(targets, dim=0)\n\n    # Create a dictionary to hold the input data\n    inputs = {\n        \"pixel_values\": images,\n        \"ground_truth_mask\": masks,\n        \"input_boxes\": targets\n    }\n\n    return inputs\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T19:16:20.632596Z","iopub.execute_input":"2023-07-11T19:16:20.632971Z","iopub.status.idle":"2023-07-11T19:16:20.642343Z","shell.execute_reply.started":"2023-07-11T19:16:20.632936Z","shell.execute_reply":"2023-07-11T19:16:20.641365Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True,collate_fn=collate_fn)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-11T19:16:20.644102Z","iopub.execute_input":"2023-07-11T19:16:20.644438Z","iopub.status.idle":"2023-07-11T19:16:20.655833Z","shell.execute_reply.started":"2023-07-11T19:16:20.644407Z","shell.execute_reply":"2023-07-11T19:16:20.654857Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"batch = next(iter(train_dataloader))\nfor k,v in batch.items():\n  print(k,v.shape)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T19:18:50.140120Z","iopub.execute_input":"2023-07-11T19:18:50.140496Z","iopub.status.idle":"2023-07-11T19:18:50.324601Z","shell.execute_reply.started":"2023-07-11T19:18:50.140466Z","shell.execute_reply":"2023-07-11T19:18:50.323632Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"pixel_values torch.Size([2, 3, 1024, 1024])\nground_truth_mask torch.Size([2, 256, 256])\ninput_boxes torch.Size([2, 86, 4])\n","output_type":"stream"}]}]}