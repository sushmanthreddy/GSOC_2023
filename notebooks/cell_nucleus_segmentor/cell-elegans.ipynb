{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q optuna\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-10T19:03:56.625036Z","iopub.execute_input":"2023-07-10T19:03:56.625429Z","iopub.status.idle":"2023-07-10T19:04:11.276986Z","shell.execute_reply.started":"2023-07-10T19:03:56.625372Z","shell.execute_reply":"2023-07-10T19:04:11.275767Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install  -q monai\n","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:04:11.280096Z","iopub.execute_input":"2023-07-10T19:04:11.281544Z","iopub.status.idle":"2023-07-10T19:04:23.656531Z","shell.execute_reply.started":"2023-07-10T19:04:11.281502Z","shell.execute_reply":"2023-07-10T19:04:23.655349Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q albumentations","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:04:23.660605Z","iopub.execute_input":"2023-07-10T19:04:23.660923Z","iopub.status.idle":"2023-07-10T19:04:35.282807Z","shell.execute_reply.started":"2023-07-10T19:04:23.660894Z","shell.execute_reply":"2023-07-10T19:04:35.281647Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q git+https://github.com/huggingface/transformers.git","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:04:35.286881Z","iopub.execute_input":"2023-07-10T19:04:35.287206Z","iopub.status.idle":"2023-07-10T19:05:19.976244Z","shell.execute_reply.started":"2023-07-10T19:04:35.287175Z","shell.execute_reply":"2023-07-10T19:05:19.974965Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os,sys\nimport numpy as np \nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom PIL import Image \nfrom tqdm.notebook import tqdm\nfrom IPython.display import clear_output","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:05:19.977890Z","iopub.execute_input":"2023-07-10T19:05:19.978278Z","iopub.status.idle":"2023-07-10T19:05:20.234202Z","shell.execute_reply.started":"2023-07-10T19:05:19.978239Z","shell.execute_reply":"2023-07-10T19:05:20.233199Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#all required torch libraries\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader,Dataset\nfrom torchvision import transforms,utils\nimport torchvision.transforms as transforms\nfrom torchvision.transforms import ToTensor\nfrom torchvision.transforms import ToPILImage\nfrom torch.utils.data.dataset import random_split\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torchvision.ops import masks_to_boxes\nfrom albumentations import Compose, Transpose, VerticalFlip, HorizontalFlip, RandomRotate90, ShiftScaleRotate, OpticalDistortion","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:05:20.235789Z","iopub.execute_input":"2023-07-10T19:05:20.236165Z","iopub.status.idle":"2023-07-10T19:05:25.264716Z","shell.execute_reply.started":"2023-07-10T19:05:20.236120Z","shell.execute_reply":"2023-07-10T19:05:25.263531Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\nimport time\nimport optuna\nimport csv\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\"finished\")\nfrom os import listdir\nfrom os.path import isfile, join","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:05:25.266257Z","iopub.execute_input":"2023-07-10T19:05:25.266610Z","iopub.status.idle":"2023-07-10T19:05:25.771150Z","shell.execute_reply.started":"2023-07-10T19:05:25.266577Z","shell.execute_reply":"2023-07-10T19:05:25.770097Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"finished\n","output_type":"stream"}]},{"cell_type":"code","source":"import monai","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:05:25.773757Z","iopub.execute_input":"2023-07-10T19:05:25.774433Z","iopub.status.idle":"2023-07-10T19:05:36.289035Z","shell.execute_reply.started":"2023-07-10T19:05:25.774380Z","shell.execute_reply":"2023-07-10T19:05:36.288036Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"def resize(path):\n  dirs = os.listdir( path )\n  for item in tqdm(dirs):\n    if os.path.isfile(path+item):\n      im = Image.open(path+item)\n      f, e = os.path.splitext(path+item)\n      imResize = im.resize((256,256), Image.NEAREST)\n      imResize.save(f+e, 'PNG', quality=100)\n      \nlabel_path =  \"/kaggle/input/nucleus-data-c-elegans/nucleus_data/segmentation_maps\"\noutput_features_path = \"/kaggle/input/nucleus-data-c-elegans/nucleus_data/features\"\nresize(label_path)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:05:36.290589Z","iopub.execute_input":"2023-07-10T19:05:36.291449Z","iopub.status.idle":"2023-07-10T19:05:40.814747Z","shell.execute_reply.started":"2023-07-10T19:05:36.291406Z","shell.execute_reply":"2023-07-10T19:05:40.813766Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6790 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fad8f99a7e5456681468d260da04777"}},"metadata":{}}]},{"cell_type":"code","source":"ids=[]\nlabel_filenames = [f for f in listdir(label_path) if isfile(join(label_path, f))]\nfeature_filenames = [f for f in listdir(output_features_path) if isfile(join(output_features_path, f))]\nfor i in range(len(feature_filenames)):\n  ids.append(feature_filenames[i][1:])\nprint(len(ids))\n\ndf = pd.DataFrame(ids ,columns=[\"file_ids\"])\ndf.to_csv('full_file_ids.csv', index=False)\n\n#sanity check\ndf = pd.read_csv('full_file_ids.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:05:40.819301Z","iopub.execute_input":"2023-07-10T19:05:40.820029Z","iopub.status.idle":"2023-07-10T19:06:22.682720Z","shell.execute_reply.started":"2023-07-10T19:05:40.819993Z","shell.execute_reply":"2023-07-10T19:06:22.681596Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"6756\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"     file_ids\n0  182_22.png\n1  167_27.png\n2   86_29.png\n3  154_16.png\n4   177_8.png","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>182_22.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>167_27.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>86_29.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>154_16.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>177_8.png</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.read_csv('full_file_ids.csv')\nids = df['file_ids'].tolist()\nnon_empty_ids = []\n\nfor file_id in ids:\n    mask_path = os.path.join(label_path + '/L' + file_id)\n    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n    if cv2.countNonZero(mask) > 0:\n        non_empty_ids.append(file_id)\n        \n        \ndf_non_empty = pd.DataFrame(non_empty_ids, columns=[\"file_ids\"])\ndf_non_empty.to_csv('file_ids.csv', index=False)\ndf = pd.read_csv('file_ids.csv')\ndf.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:06:22.684365Z","iopub.execute_input":"2023-07-10T19:06:22.684836Z","iopub.status.idle":"2023-07-10T19:07:13.828307Z","shell.execute_reply.started":"2023-07-10T19:06:22.684800Z","shell.execute_reply":"2023-07-10T19:07:13.827105Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"     file_ids\n0  182_22.png\n1  167_27.png\n2   86_29.png\n3  154_16.png\n4   177_8.png","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>182_22.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>167_27.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>86_29.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>154_16.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>177_8.png</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pip install 'transformers[torch]'","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:07:13.830450Z","iopub.execute_input":"2023-07-10T19:07:13.831085Z","iopub.status.idle":"2023-07-10T19:07:25.695452Z","shell.execute_reply.started":"2023-07-10T19:07:13.831048Z","shell.execute_reply":"2023-07-10T19:07:25.693837Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.31.0.dev0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.12.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (5.4.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.5.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.28.2)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.3.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.64.1)\nRequirement already satisfied: torch!=1.12.0,>=1.9 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.0.0)\nCollecting accelerate>=0.20.3 (from transformers[torch])\n  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (2023.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.0.9)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2023.5.7)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\nInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.12.0\n    Uninstalling accelerate-0.12.0:\n      Successfully uninstalled accelerate-0.12.0\nSuccessfully installed accelerate-0.20.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"class SegmentationDataset(Dataset):\n    def __init__(self, csv, processor):\n        self.df = pd.read_csv(csv)\n        self.ids = self.df[\"file_ids\"]\n        self.processor = processor\n        \n\n    def __getitem__(self, idx):\n        image = Image.open(\"/kaggle/input/nucleus-data-c-elegans/nucleus_data/features/F\" + self.ids[idx])\n        mask = np.array(Image.open(\"/kaggle/input/nucleus-data-c-elegans/nucleus_data/segmentation_maps/L\" + self.ids[idx]))\n            \n\n        prompt = self.mask_to_boxes(mask)\n\n        inputs = self.processor(image, input_boxes=[prompt], return_tensors=\"pt\")\n        inputs = {k: v.squeeze(0) for k, v in inputs.items()}\n\n        inputs[\"ground_truth_mask\"] = mask\n\n        return inputs\n\n    def __len__(self):\n        return len(self.ids)\n    \n    \n    @staticmethod\n    def mask_to_boxes(mask):\n        obj_id=np.unique(mask)\n        obj_ids=obj_id[1:]\n        maskes = mask == obj_ids[:, None, None]\n        b_boxes=[]\n        num_objs=len(obj_ids)\n        for i in range(num_objs):\n            pos=np.nonzero(maskes[i])\n            xmin=np.min(pos[1])\n            xmax=np.max(pos[1])\n            ymin=np.min(pos[0])\n            ymax=np.max(pos[0])\n            b_boxes.append([xmin,ymin,xmax,ymax])\n        \n        return b_boxes\n            \n            ","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:07:25.697204Z","iopub.execute_input":"2023-07-10T19:07:25.697610Z","iopub.status.idle":"2023-07-10T19:07:25.710515Z","shell.execute_reply.started":"2023-07-10T19:07:25.697571Z","shell.execute_reply":"2023-07-10T19:07:25.709369Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from transformers import SamProcessor\n\nprocessor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:07:25.712324Z","iopub.execute_input":"2023-07-10T19:07:25.713620Z","iopub.status.idle":"2023-07-10T19:07:26.204337Z","shell.execute_reply.started":"2023-07-10T19:07:25.713585Z","shell.execute_reply":"2023-07-10T19:07:26.203374Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)rocessor_config.json:   0%|          | 0.00/466 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f221407a78354f498b7af3101ab2ced9"}},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = SegmentationDataset(csv = \"file_ids.csv\", processor=processor)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:07:26.206084Z","iopub.execute_input":"2023-07-10T19:07:26.206824Z","iopub.status.idle":"2023-07-10T19:07:26.219374Z","shell.execute_reply.started":"2023-07-10T19:07:26.206789Z","shell.execute_reply":"2023-07-10T19:07:26.218464Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"example = train_dataset[4235]\nfor k,v in example.items():\n  print(k,v.shape)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:07:26.221061Z","iopub.execute_input":"2023-07-10T19:07:26.221737Z","iopub.status.idle":"2023-07-10T19:07:26.363030Z","shell.execute_reply.started":"2023-07-10T19:07:26.221703Z","shell.execute_reply":"2023-07-10T19:07:26.362075Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"pixel_values torch.Size([3, 1024, 1024])\noriginal_sizes torch.Size([2])\nreshaped_input_sizes torch.Size([2])\ninput_boxes torch.Size([20, 4])\nground_truth_mask (256, 256)\n","output_type":"stream"}]},{"cell_type":"code","source":"def collate_fn(batch):\n    images = []\n    masks = []\n    boxes = []\n\n    for item in batch:\n        images.append(item[\"pixel_values\"])\n        masks.append(item[\"ground_truth_mask\"])\n        boxes.append(item[\"input_boxes\"])\n\n    # Stack images and masks into tensors\n    images = torch.stack(images, dim=0)\n    masks = torch.stack([torch.from_numpy(mask) for mask in masks], dim=0)\n\n    # Create a list of targets with variable number of boxes per sample\n    targets = []\n    max_num_boxes = max(len(b) for b in boxes)\n    for b in boxes:\n        padded_boxes = torch.cat([b, torch.zeros((max_num_boxes - len(b), 4))], dim=0)\n        targets.append(padded_boxes)\n\n    # Create a dictionary to hold the input data\n    inputs = {\n        \"pixel_values\": images,\n        \"ground_truth_mask\": masks,\n        \"input_boxes\": targets\n    }\n\n    return inputs\n","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:13:13.337477Z","iopub.execute_input":"2023-07-10T19:13:13.338164Z","iopub.status.idle":"2023-07-10T19:13:13.346012Z","shell.execute_reply.started":"2023-07-10T19:13:13.338131Z","shell.execute_reply":"2023-07-10T19:13:13.344888Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True,collate_fn=collate_fn)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:13:18.240904Z","iopub.execute_input":"2023-07-10T19:13:18.241284Z","iopub.status.idle":"2023-07-10T19:13:18.246491Z","shell.execute_reply.started":"2023-07-10T19:13:18.241252Z","shell.execute_reply":"2023-07-10T19:13:18.245446Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"batch = next(iter(train_dataloader))\nfor k,v in batch.items():\n  print(k,v.shape)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:13:22.676157Z","iopub.execute_input":"2023-07-10T19:13:22.676642Z","iopub.status.idle":"2023-07-10T19:13:22.951101Z","shell.execute_reply.started":"2023-07-10T19:13:22.676596Z","shell.execute_reply":"2023-07-10T19:13:22.948169Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"pixel_values torch.Size([2, 3, 1024, 1024])\nground_truth_mask torch.Size([2, 256, 256])\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[40], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_dataloader))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 3\u001b[0m   \u001b[38;5;28mprint\u001b[39m(k,\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"],"ename":"AttributeError","evalue":"'list' object has no attribute 'shape'","output_type":"error"}]},{"cell_type":"code","source":"batch[\"input_boxes\"]","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:09:54.508537Z","iopub.execute_input":"2023-07-10T19:09:54.509650Z","iopub.status.idle":"2023-07-10T19:09:54.533322Z","shell.execute_reply.started":"2023-07-10T19:09:54.509609Z","shell.execute_reply":"2023-07-10T19:09:54.532379Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"[[tensor([[168., 584., 196., 624.],\n          [156., 500., 156., 504.],\n          [168., 404., 192., 444.],\n          [208., 324., 248., 384.],\n          [232., 284., 288., 348.],\n          [172., 604., 192., 640.],\n          [188., 580., 224., 640.],\n          [184., 640., 224., 696.],\n          [216., 656., 260., 724.],\n          [204., 516., 220., 544.],\n          [276., 664., 300., 704.],\n          [152., 488., 160., 500.],\n          [156., 492., 192., 556.],\n          [172., 380., 208., 444.],\n          [200., 356., 236., 404.],\n          [200., 436., 232., 496.],\n          [240., 404., 264., 440.],\n          [288., 332., 336., 396.],\n          [232., 716., 236., 720.],\n          [252., 756., 264., 792.],\n          [256., 760., 300., 824.],\n          [292., 804., 316., 812.],\n          [316., 784., 360., 856.],\n          [244., 692., 292., 760.],\n          [292., 740., 336., 792.],\n          [344., 752., 396., 812.],\n          [408., 760., 456., 828.],\n          [192., 504., 200., 512.],\n          [228., 516., 264., 564.],\n          [404., 584., 412., 624.],\n          [212., 432., 244., 480.],\n          [296., 468., 324., 500.],\n          [260., 404., 272., 420.],\n          [312., 396., 316., 396.],\n          [456., 324., 480., 352.],\n          [684., 716., 708., 756.],\n          [736., 688., 748., 716.],\n          [796., 640., 832., 696.],\n          [504., 228., 528., 264.],\n          [552., 224., 584., 260.],\n          [600., 208., 624., 232.],\n          [676., 228., 708., 280.],\n          [716., 292., 756., 340.],\n          [800., 332., 836., 392.],\n          [292., 580., 328., 624.],\n          [512., 656., 524., 660.],\n          [244., 700., 280., 724.],\n          [356., 752., 376., 788.],\n          [412., 828., 440., 852.],\n          [464., 784., 504., 852.],\n          [508., 808., 560., 872.],\n          [568., 816., 608., 864.],\n          [508., 748., 524., 776.],\n          [548., 720., 576., 768.],\n          [580., 772., 612., 824.],\n          [628., 776., 676., 828.],\n          [740., 708., 784., 772.],\n          [788., 708., 828., 764.],\n          [824., 696., 824., 696.],\n          [808., 696., 816., 696.],\n          [632., 808., 664., 836.],\n          [680., 748., 724., 816.],\n          [360., 812., 372., 848.],\n          [356., 800., 368., 824.],\n          [440., 804., 460., 836.],\n          [284., 224., 312., 264.],\n          [364., 212., 384., 240.],\n          [292., 304., 320., 340.],\n          [316., 260., 356., 324.],\n          [360., 256., 408., 300.],\n          [408., 224., 452., 272.],\n          [284., 328., 288., 348.],\n          [364., 228., 408., 292.],\n          [408., 228., 456., 284.],\n          [416., 164., 460., 212.],\n          [460., 172., 508., 228.],\n          [500., 200., 548., 264.],\n          [552., 192., 596., 260.],\n          [588., 164., 628., 220.],\n          [632., 184., 668., 216.],\n          [744., 260., 792., 324.],\n          [788., 296., 824., 332.],\n          [692., 212., 728., 264.],\n          [744., 264., 756., 280.],\n          [408., 216., 436., 232.],\n          [468., 220., 496., 228.],\n          [188., 516., 200., 552.],\n          [220., 492., 264., 556.],\n          [284., 572., 324., 616.],\n          [344., 528., 388., 596.],\n          [280., 544., 324., 600.],\n          [348., 524., 388., 568.],\n          [388., 468., 428., 540.],\n          [448., 576., 448., 576.],\n          [352., 656., 392., 708.],\n          [356., 628., 404., 696.],\n          [436., 712., 456., 740.],\n          [484., 652., 540., 724.],\n          [256., 404., 304., 464.],\n          [284., 440., 324., 496.],\n          [352., 448., 388., 516.],\n          [364., 412., 392., 452.],\n          [444., 380., 484., 432.],\n          [392., 324., 432., 380.],\n          [404., 324., 452., 384.],\n          [496., 308., 500., 324.],\n          [496., 288., 548., 356.],\n          [412., 564., 456., 632.],\n          [504., 504., 544., 568.],\n          [560., 544., 604., 620.],\n          [432., 428., 480., 496.],\n          [528., 420., 576., 484.],\n          [528., 432., 528., 432.],\n          [580., 492., 616., 556.],\n          [656., 540., 704., 604.],\n          [704., 508., 748., 576.],\n          [556., 352., 600., 416.],\n          [628., 356., 672., 428.],\n          [652., 428., 696., 492.],\n          [816., 564., 820., 568.],\n          [828., 572., 876., 636.],\n          [696., 672., 716., 708.],\n          [816., 428., 876., 496.],\n          [712., 316., 736., 356.],\n          [512., 708., 548., 776.],\n          [572., 696., 620., 768.],\n          [580., 696., 620., 760.],\n          [628., 632., 676., 708.],\n          [536., 292., 536., 292.],\n          [628., 276., 680., 328.]], dtype=torch.float64),\n  tensor([[156., 556., 204., 620.],\n          [200., 600., 264., 700.],\n          [276., 692., 344., 792.],\n          [216., 708., 252., 760.],\n          [168., 384., 224., 472.],\n          [236., 324., 292., 400.],\n          [216., 408., 268., 480.],\n          [308., 380., 348., 440.],\n          [272., 232., 332., 328.],\n          [380., 300., 428., 368.],\n          [396., 220., 460., 312.],\n          [492., 284., 524., 344.],\n          [472., 828., 512., 876.],\n          [560., 816., 612., 884.],\n          [684., 808., 736., 864.],\n          [708., 300., 708., 300.],\n          [756., 324., 800., 392.],\n          [444., 160., 512., 244.],\n          [548., 172., 604., 268.],\n          [524., 256., 572., 336.],\n          [612., 296., 652., 364.],\n          [628., 172., 692., 264.],\n          [672., 304., 736., 384.],\n          [736., 296., 784., 372.],\n          [808., 392., 876., 488.],\n          [228., 520., 284., 596.],\n          [336., 540., 392., 624.],\n          [356., 624., 404., 704.],\n          [492., 636., 536., 712.],\n          [388., 684., 440., 768.],\n          [508., 712., 544., 772.],\n          [524., 708., 576., 788.],\n          [632., 724., 672., 792.],\n          [316., 372., 368., 464.],\n          [428., 456., 484., 532.],\n          [444., 488., 488., 556.],\n          [584., 508., 628., 572.],\n          [440., 340., 492., 412.],\n          [524., 412., 580., 484.],\n          [560., 404., 612., 472.],\n          [664., 432., 712., 500.],\n          [552., 608., 568., 632.],\n          [724., 676., 764., 772.],\n          [808., 556., 852., 620.],\n          [684., 552., 716., 588.],\n          [612., 652., 640., 696.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.],\n          [  0.,   0.,   0.,   0.]], dtype=torch.float64)]]"},"metadata":{}}]}]}